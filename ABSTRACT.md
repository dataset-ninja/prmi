The **PRMI: Plant Root Minirhizotron Imagery** dataset features over 72,000 RGB root images, encompassing six distinct plant species: ***cotton***, ***papaya***, ***peanut***, ***sesame***, ***sunflower***, and ***switchgrass***. These images cover a wide range of conditions, including varying root ages, structures, soil types, and depths beneath the soil surface. All images come with image-level labels indicating the presence or absence of roots, facilitating weakly supervised learning for root segmentation tasks. Additionally, more than 63,000 images have been manually annotated with pixel-level binary masks, serving as ground truth data for supervised learning in semantic segmentation tasks. The primary objective of introducing this dataset is to streamline the automatic segmentation of plant roots and advance RSA research through deep learning and other image analysis techniques.

<img src="https://github.com/dataset-ninja/gland-segmentation/assets/78355358/97bdd1df-e4fb-41f2-97dc-59d1bd8387cb" alt="image" width="400">

In the authors' study, a comprehensive dataset of plant root images obtained through Minirhizotron (MR) technology is introduced and meticulously curated. This dataset proves invaluable for understanding a plant's root system architecture (RSA), a critical aspect of various plant science domains, including sustainability and climate adaptation. MR technology offers a non-destructive approach to phenotyping RSA by capturing root imagery over time, and the accurate segmentation of roots from the soil in MR imagery is vital for RSA analysis.

<img src="https://github.com/dataset-ninja/gland-segmentation/assets/78355358/211ae3e5-3ac2-48c1-bae4-331c6f5cd963" alt="image" width="800">

The authors underscore the pivotal role of plant root systems in supporting natural ecosystems, adapting to climate variations, and ensuring sustainable plant production. Phenotyping RSA is crucial for understanding these systems and advancing various aspects of plant science research.

They emphasize the challenges associated with below-ground field-based plant root phenotyping, highlighting that traditional methods like soil coring and "shovelomics" are destructive, labor-intensive, time-consuming, and unsuitable for real-time or longitudinal studies. In contrast, MR technology, wherein transparent tubes are installed in the soil to capture root images over time, offers a non-destructive and high-resolution alternative. MR imagery provides insights into root system development and changes in root characteristics over their life cycle, such as color, diameter, angle, and length changes.

Precise root segmentation from soil backgrounds in MR imagery is a crucial step for effectively utilizing MR technology for RSA analysis. Manual annotation of MR images, wherein users trace individual roots, is a tedious and time-consuming task. This annotation process is a significant bottleneck in large-scale RSA studies. Due to the complexity of plant RSA, biological variability, and environmental influences, a substantial amount of data is required to draw statistically sound conclusions. Therefore, efficient algorithms for high-throughput automatic root segmentation are essential.

The PRMI dataset, curated by the authors, features MR-captured root images across various plant species. Each species' dataset includes images from multiple plants and MR tubes, captured at different depths, times, and under diverse soil and environmental conditions. Notably, images related to a specific species may capture the same root portions at different stages of growth, size, shape, and color. Despite all images being captured using MR technology, variations exist in the technology's specifics for each sub-collection, such as camera types, image resolutions, DPI, and color profiles. Some images exclusively contain plant roots, while others solely depict soil and background.

Each MR image in this dataset is complemented by image-level annotations. Additionally, over 63,000 images are paired with pixel-level annotations, comprising segmentation masks indicating whether each pixel corresponds to a root or soil. Pixel-level annotation methods vary for different species: for cotton, papaya, peanut, sesame, and sunflower, the WinRHIZO Tron software is used, while for switchgrass, annotations are based on superpixels generated by the SLIC algorithm or refined using pre-trained U-net models.

The dataset's careful curation allows for various types of analysis, including weakly supervised learning for root segmentation tasks. Meta-data for each MR image, including crop species, collection details, tube numbers, depth, and sensor DPI, is recorded in JSON format, providing a comprehensive understanding of the dataset's characteristics.

To ensure balanced data distribution among ***train***, ***val***, and ***test*** sets while avoiding overlap between them, the authors divided the data based on MR tubes. For most species, 60% of tubes were allocated to training, 20% to validation, and the remaining 20% to testing. For switchgrass, all images with manually generated ground-truth masks were placed in the test set, ensuring test set accuracy. The training set included images with image-level annotations to support weakly supervised segmentation.

|Species|DPI|Size|Num of locations|Num of tubes|Num of root images|Num of non-root images|Train|Val|Test|Total|
|-------|---|----|----------------|------------|------------------|----------------------|-----|---|----|-----|
|Cotton|150|736×552|1|12|918|1494|1271|564|577|2412|
|Papaya|150|736×552|2|6|487|59|282|131|133|546|
|Peanut|120|640×480|1|32|8508|8534|10087|3413|3542|17042|
|Peanut|150|736×552|2|24|11147|8478|11485|3347|4793|19625|
|Sesame|120|640×480|4|11|1460|700|1438|318|404|2160|
|Sesame|150|736×552|2|24|7923|6423|8637|2625|3084|14346|
|Sunflower|120|640×480|1|16|1646|2254|2211|722|967|3900|
|Switchgrass|300|510×720|3|72|3465|9072|11272∗|665|600|12537|

<span style="font-size: smaller; font-style: italic;">∗2647 images in the training set have pixel-level annotation and the remaining 8625 images only have image-level annotation.</span>

Researchers can further customize dataset splits based on attributes such as dates, depths, and locations for specific research questions. The inclusion of image-level labels with meta-data facilitates dataset sorting and splitting based on different criteria.
